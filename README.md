<h1>Project Serials-Movies & Webseries Recommendation System</h1>
<b>Status: On Progress</b><br><br>
<b>College name: Hooghly Engineering and Technology College</b><br>
<b>Project type: Final Year Project</b><br>
<b>Mentor: <a href="https://www.hetc.ac.in/faculty/sanghamitra-das/">Prof. Mr. Sanghamitra Das</a> (Assistant Prof, Computer Science and Engineering Dept.)</b><br><br>
<br><b>Project Started: 1 October 2021</b><br>
<b>Project Ended: Currently ongoing...</b><br><br>
<b>Click here to see <a href="https://drive.google.com/file/d/1YHhe3_jNbAht1zaHw1jypey04VXyBpUy/view?usp=sharing">project documentation</a></b><br><br>
<b>Project Group Members:</b>
<ol>
  <br><li><a href="https://www.linkedin.com/in/soumoofficial/">Soumodip Ghosh</a> (CSE Dept., Year of Passing 2022)</li>
  <li><a href="https://www.linkedin.com/in/jayanta-dhali-8a3326192/">Jayanta Dhali</a> (CSE Dept., Year of Passing 2022)</li>
  <li><a href="https://www.linkedin.com/in/ankitadofficial/">Ankita Datta</a> (CSE Dept., Year of Passing 2022)</li>
  <li><a href="https://www.linkedin.com/in/sarthak-srivastava-50b47a205/">Sarthak Srivastava</a> (CSE Dept., Year of Passing 2022)</li>
</ol>
<br><b>Project Started: 1 October 2021</b><br>
<b>Project Ended: Currently ongoing...</b><br><br>
For any queries contact me at <a href="mailto:ghoshsoumo14@gmail.com"><b>ghoshsoumo14@gmail.com</b></a>

<div class="container">
     <div class="p-4 p-md-5 mb-4 text-white rounded bg-dark">
                <div class="col-md-6 px-0">
                    <h1 class="display-4 fst-italic">Dive deep into the world of Data Mining and RS</h1>
                    <p class="lead my-3">Get brief idea on the concept of Data Mining and how the thought of a RS came into people's mind.</p>
                </div>
            </div>
        <div class="row align-items-md-stretch">
            <div class="col-md-6">
                <div class="h-100 p-5 text-dark bg-light rounded-3">
                    <h2>Data Mining</h2>
                    <p>The process of digging through data to discover hidden connections and predict future trends has a long history. Sometimes referred to as "knowledge discovery in databases," the term "data mining" wasn’t coined until the 1990s. But its foundation comprises three intertwined scientific disciplines: statistics (the numeric study of data relationships), artificial intelligence (human-like intelligence displayed by software and/or machines) and machine learning (algorithms that can learn from data to make predictions). What was old is new again, as data mining technology keeps evolving to keep pace with the limitless potential of big data and affordable computing power.
                        Over the last decade, advances in processing power and speed have enabled us to move beyond manual, tedious and time-consuming practices to quick, easy and automated data analysis. The more complex the data sets collected, the more potential there is to uncover relevant insights. Retailers, banks, manufacturers, telecommunications providers and insurers, among others, are using data mining to discover relationships among everything from price optimization, promotions and demographics to how the economy, risk, competition and social media are affecting their business models, revenues, operations and customer relationships.</p>
                    
                </div>
            </div>
            <div class="col-md-6">
                <div class="h-100 p-5 bg-dark border text-light rounded-3">
                    <h2>Recommendation System</h2>
                    <p>A Recommendation System (RS) is an intelligent computer-based technique that predicts on the basis of users’ adoption and usage and helps them to pick items from a vast pool of online stuffs. Most internet users surely have happened upon an RS in some way. For instance, Facebook recommends us, prospective friends, YouTube recommends us the videos in accord, Glassdoor recommends us matching jobs, Goodreads recommends us interesting books and so on. E-Commerce portals (e.g., eBay, Amazon, etc.) are using RSs to entice customers by heaving with the products that customers should, presumably, going to like. This has helped them to attain a huge boost in sales. Not only the online business, but there are other applications also that take advantage of RSs, such as social networks, online news portals, entertainment sites, and other knowledge management applications.These days, many companies are adopting RS techniques as an added value to enrich their client services. Though, the implementation of an RS depends on the particular recommendation approach adopted by the application, the core working of RSs remain more or less the same for all applications. The focal objective of RSs is to aid users in their decision making in order to pick out an online item, by supporting with in-hand recommendations of high accuracy. </p>
                    
                </div>
            </div>
        </div>
        <!-- From here the blog on Data Mining and Recommender System Starts -->
        <main class="container my-4">
            <div class="row mb-2">
                <div class="col-md-6">
                    <div class="row g-0 border rounded overflow-hidden flex-md-row mb-4 shadow-sm h-md-250 position-relative">
                        <div class="col p-4 d-flex flex-column position-static">
                            <strong class="d-inline-block mb-2 text-primary">DM</strong>
                            <h3 class="mb-0">Data Mining</h3>
                            <div class="mb-1 text-muted">Apr 27</div>
                            <p class="card-text mb-auto">Read about the history of Data Mining in more details.</p>
                            <a href="https://medium.com/@exastax/the-history-of-data-mining-d2aeb0f587ce" class="stretched-link">Continue reading</a>
                        </div>
                        <div class="col-auto d-none d-lg-block">
                            <img class="bd-placeholder-img" width="200" height="250" src="https://cyberhoot.com/wp-content/uploads/2020/06/data-mining-illustration.jpg" role="img" preserveAspectRatio="xMidYMid slice" focusable="false">
                            <title></title>
                            <rect width="100%" height="100%" fill="#55595c"></rect></img>
                        </div>
                    </div>
                </div>
                <div class="col-md-6">
                    <div class="row g-0 border rounded overflow-hidden flex-md-row mb-4 shadow-sm h-md-250 position-relative">
                        <div class="col p-4 d-flex flex-column position-static">
                            <strong class="d-inline-block mb-2 text-success">RS</strong>
                            <h3 class="mb-0">Recommendation System</h3>
                            <div class="mb-1 text-muted">Apr 29</div>
                            <p class="mb-auto">Read about the history of Recommendation Systems in more details.</p>
                            <a href="https://www.onespire.net/news/history-of-recommender-systems/" class="stretched-link">Continue reading</a>
                        </div>
                        <div class="col-auto d-none d-lg-block">
                            <img class="bd-placeholder-img" width="200" height="250" src="https://miro.medium.com/max/792/1*P63ZaFHlssabl34XbJgong.jpeg" role="img" preserveAspectRatio="xMidYMid slice" focusable="false">
                            <title></title>
                            <rect width="100%" height="100%" fill="#55595c"></rect></img>
                        </div>
                    </div>
                </div>
            </div>
            <div class="row g-5">
                <div class="col-md-8">
                    <h3 class="pb-4 mb-4 fst-italic border-bottom">
                        From the Team
                    </h3>
                    <article class="blog-post">
                        <h2 class="blog-post-title">Blog on Data Mining</h2>
                        <p class="blog-post-meta">April 27, 2022 by <a href="https://www.linkedin.com/in/soumoofficial/">Soumo</a></p>
                        <p>This blog post is about the details and purpose of developing a Data Mining <Project></Project>. This blog post also includes the detailed process of developing a Data Mining model.</p>
                        <hr>
                        <p>Data mining is a process of extracting and discovering patterns in large data sets involving methods at the intersection of machine learning, statistics, and database systems.</p>
                        <h2>Introduction</h2>
                        <p>Data mining is a process of extracting and discovering patterns in large data sets involving methods at the intersection of machine learning, statistics, and database systems. Data mining is an interdisciplinary subfield of computer science and statistics with an overall goal of extracting information (with intelligent methods) from a data set and transform the information into a comprehensible structure for further use. Data mining is the analysis step of the "knowledge discovery in databases" process, or KDD. Aside from the raw analysis step, it also involves database and data management aspects, data pre-processing, model and inference considerations, interestingness metrics, complexity considerations, post-processing of discovered structures, visualization, and online updating</p>
                        <blockquote class="blockquote">
                            <p>Meaning</p>
                        </blockquote>
                        <p>The term "data mining" is a misnomer because the goal is the extraction of patterns and knowledge from large amounts of data, not the extraction (mining) of data itself.</p>
                        <h3>Background</h3>
                        <p>The manual extraction of patterns from data has occurred for centuries. Early methods of identifying patterns in data include Bayes' theorem (1700s) and regression analysis (1800s). The proliferation, ubiquity and increasing power of computer technology have dramatically increased data collection, storage, and manipulation ability. As data sets have grown in size and complexity, direct "hands-on" data analysis has increasingly been augmented with indirect, automated data processing, aided by other discoveries in computer science, specially in the field of machine learning, such as neural networks, cluster analysis, genetic algorithms (1950s), decision trees and decision rules (1960s), and support vector machines (1990s). Data mining is the process of applying these methods with the intention of uncovering hidden patterns in large data sets. It bridges the gap from applied statistics and artificial intelligence (which usually provide the mathematical background) to database management by exploiting the way data is stored and indexed in databases to execute the actual learning and discovery algorithms more efficiently, allowing such methods to be applied to ever-larger data sets</p>
                        <h3>Process</h3>
                        <p>The knowledge discovery in databases (KDD) process is commonly defined with the stages:</p>
                        <ul>
                            <li>Selection</li>
                            <li>Pre-processing</li>
                            <li>Transformation</li>
                            <li>Data mining</li>
                            <li>Interpretation/Evaluation</li>
                        </ul>
                        <p>It exists, however, in many variations on this theme, such as the Cross-industry standard process for data mining (CRISP-DM) which defines six phases:</p>
                        <ol>
                            <li>Business understanding</li>
                            <li>Data understanding</li>
                            <li>Data preparation</li>
                            <li>Modeling</li>
                            <li>Evaluation</li>
                            <li>Deployment</li>
                        </ol>
                        <h3>Pre-processing</h3>
                        <p>Before data mining algorithms can be used, a target data set must be assembled. As data mining can only uncover patterns actually present in the data, the target data set must be large enough to contain these patterns while remaining concise enough to be mined within an acceptable time limit. A common source for data is a data mart or data warehouse. Pre-processing is essential to analyze the multivariate data sets before data mining. The target set is then cleaned. Data cleaning removes the observations containing noise and those with missing data.</p>
                        <h3>Data mining</h3>
                        <p>Data mining involves six common classes of tasks:</p>
                        <ol>
                            <li><b>Anomaly detection (outlier/change/deviation detection)</b> – The identification of unusual data records, that might be interesting or data errors that require further investigation.</li>
                            <li><b>Association rule learning (dependency modeling)</b> – Searches for relationships between variables. For example, a supermarket might gather data on customer purchasing habits. Using association rule learning, the supermarket can determine which products are frequently bought together and use this information for marketing purposes. This is sometimes referred to as market basket analysis.</li>
                            <li><b>Clustering</b> – is the task of discovering groups and structures in the data that are in some way or another "similar", without using known structures in the data.</li>
                            <li><b>Classification</b> – is the task of generalizing known structure to apply to new data. For example, an e-mail program might attempt to classify an e-mail as "legitimate" or as "spam".</li>
                            <li><b>Regression</b> – attempts to find a function that models the data with the least error that is, for estimating the relationships among data or datasets.</li>
                            <li><b>Summarization</b> – providing a more compact representation of the data set, including visualization and report generation.</li>
                        </ol>
                    </article>
                    <article class="blog-post">
                        <h2 class="blog-post-title">Blog on our Recommendation System</h2>
                        <p class="blog-post-meta">April 27, 2022 by <a href="https://www.linkedin.com/in/jayanta-dhali-8a3326192/">Jayanta</a></p>
                        <p>This blog post is about the details and purpose of developing a Recommendation System <Project></Project>. This blog post also includes the detailed process of developing a Recommendation System.</p>
                        <hr>
                        <p>A Recommender system, or a recommendation system (sometimes replacing 'system' with a synonym such as platform or engine), is a subclass of information filtering system that seeks to predict the "rating" or "preference" a user would give to an item.</p>
                        <h2>Introduction</h2>
                        <p>Recommender systems usually make use of either or both collaborative filtering and content-based filtering (also known as the personality-based approach), as well as other systems such as knowledge-based systems. Collaborative filtering approaches build a model from a user's past behavior (items previously purchased or selected and/or numerical ratings given to those items) as well as similar decisions made by other users. This model is then used to predict items (or ratings for items) that the user may have an interest in. Content-based filtering approaches utilize a series of discrete, pre-tagged characteristics of an item in order to recommend additional items with similar properties</p>
                        <blockquote class="blockquote">
                            <p>Meaning</p>
                        </blockquote>
                        <p>The term "recommendation system" has two parts one is "recommendation" which means giving a suitable suggestion and "system" refers to a engine.</p>
                        <h3>Approaches</h3>
                        <ol>
                            <h5>a) Collaborative filtering</h5>
                            <p>One approach to the design of recommender systems that has wide use is collaborative filtering. Collaborative filtering is based on the assumption that people who agreed in the past will agree in the future, and that they will like similar kinds of items as they liked in the past. The system generates recommendations using only information about rating profiles for different users or items. By locating peer users/items with a rating history similar to the current user or item, they generate recommendations using this neighborhood. Collaborative filtering methods are classified as memory-based and model-based. A well-known example of memory-based approaches is the user-based algorithm, while that of model-based approaches is the Kernel-Mapping Recommender.</p>
                            <p>A key advantage of the collaborative filtering approach is that it does not rely on machine analyzable content and therefore it is capable of accurately recommending complex items such as movies without requiring an "understanding" of the item itself. Many algorithms have been used in measuring user similarity or item similarity in recommender systems. For example, the k-nearest neighbor (k-NN) approach and the Pearson Correlation as first implemented by Allen.</p>
                            <p>Collaborative filtering approaches often suffer from three problems: cold start, scalability, and sparsity.</p>
                            <ol>
                                <li><b>Cold start:</b> For a new user or item, there isn't enough data to make accurate recommendations. Note: one commonly implemented solution to this problem is the Multi-armed bandit algorithm.</li>
                                <li><b>Scalability:</b> There are millions of users and products in many of the environments in which these systems make recommendations. Thus, a large amount of computation power is often necessary to calculate recommendations.</li>
                                <li><b>Sparsity:</b> The number of items sold on major e-commerce sites is extremely large. The most active users will only have rated a small subset of the overall database. Thus, even the most popular items have very few ratings.</li>
                            </ol>
                            <p>One of the most famous examples of collaborative filtering is item-to-item collaborative filtering (people who buy x also buy y), an algorithm popularized by Amazon.com's recommender system.
                                Many social networks originally used collaborative filtering to recommend new friends, groups, and other social connections by examining the network of connections between a user and their friends.[1] Collaborative filtering is still used as part of hybrid systems.</p>
                            <h5>b) Content-based filtering</h5>
                            <p>Another common approach when designing recommender systems is content-based filtering. Content-based filtering methods are based on a description of the item and a profile of the user's preferences. These methods are best suited to situations where there is known data on an item (name, location, description, etc.), but not on the user. Content-based recommenders treat recommendation as a user-specific classification problem and learn a classifier for the user's likes and dislikes based on an item's features.</p>
                            <p>In this system, keywords are used to describe the items, and a user profile is built to indicate the type of item this user likes. In other words, these algorithms try to recommend items similar to those that a user liked in the past or is examining in the present. It does not rely on a user sign-in mechanism to generate this often temporary profile. In particular, various candidate items are compared with items previously rated by the user, and the best-matching items are recommended. This approach has its roots in information retrieval and information filtering research.</p>
                            <p>To create a user profile, the system mostly focuses on two types of information:</p>
                            <ol>
                                <li> A model of the user's preference.</li>
                                <li> A history of the user's interaction with the recommender system.</li>
                            </ol>
                            <p>Basically, these methods use an item profile (i.e., a set of discrete attributes and features) characterizing the item within the system. To abstract the features of the items in the system, an item presentation algorithm is applied. A widely used algorithm is the tf–idf representation (also called vector space representation). The system creates a content-based profile of users based on a weighted vector of item features. The weights denote the importance of each feature to the user and can be computed from individually rated content vectors using a variety of techniques. Simple approaches use the average values of the rated item vector while other sophisticated methods use machine learning techniques such as Bayesian Classifiers, cluster analysis, decision trees, and artificial neural networks in order to estimate the probability that the user is going to like the item.</p>
                            <p>A key issue with content-based filtering is whether the system can learn user preferences from users' actions regarding one content source and use them across other content types. When the system is limited to recommending content of the same type as the user is already using, the value from the recommendation system is significantly less than when other content types from other services can be recommended. For example, recommending news articles based on news browsing is useful. Still, it would be much more useful when music, videos, products, discussions, etc., from different services, can be recommended based on news browsing. To overcome this, most content-based recommender systems now use some form of the hybrid system.</p>
                            <p>Content-based recommender systems can also include opinion-based recommender systems. In some cases, users are allowed to leave text reviews or feedback on the items. These user-generated texts are implicit data for the recommender system because they are potentially rich resources of both feature/aspects of the item and users' evaluation/sentiment to the item. Features extracted from the user-generated reviews are improved meta-data of items, because as they also reflect aspects of the item like meta-data, extracted features are widely concerned by the users. Sentiments extracted from the reviews can be seen as users' rating scores on the corresponding features. Popular approaches of opinion-based recommender system utilize various techniques including text mining, information retrieval, sentiment analysis (see also Multimodal sentiment analysis) and deep learning.</p>
                            <h5>c) Session-based recommender systems</h5>
                            <p>These recommender systems use the interactions of a user within a session to generate recommendations. Session-based recommender systems are used at Youtube and Amazon. These are particularly useful when history (such as past clicks, purchases) of a user is not available or not relevant in the current user session. Domains where session-based recommendations are particularly relevant include video, e-commerce, travel, music and more. Most instances of session-based recommender systems rely on the sequence of recent interactions within a session without requiring any additional details (historical, demographic) of the user. Techniques for session-based recommendations are mainly based on generative sequential models such as Recurrent Neural Networks, Transformers, and other deep learning based approaches</p>
                            <h5>d) Reinforcement learning for recommender systems</h5>
                            <p>The manual extraction of patterns from data has occurred for centuries. Early methods of identifying patterns in data include Bayes' theorem (1700s) and regression analysis (1800s). The proliferation, ubiquity and increasing power of computer technology have dramatically increased data collection, storage, and manipulation ability. As data sets have grown in size and complexity, direct "hands-on" data analysis has increasingly been augmented with indirect, automated data processing, aided by other discoveries in computer science, specially in the field of machine learning, such as neural networks, cluster analysis, genetic algorithms (1950s), decision trees and decision rules (1960s), and support vector machines (1990s). Data mining is the process of applying these methods with the intention of uncovering hidden patterns in large data sets. It bridges the gap from applied statistics and artificial intelligence (which usually provide the mathematical background) to database management by exploiting the way data is stored and indexed in databases to execute the actual learning and discovery algorithms more efficiently, allowing such methods to be applied to ever-larger data sets</p>
                            <h5>e) Multi-criteria recommender systems</h5>
                            <p>The recommendation problem can be seen as a special instance of a reinforcement learning problem whereby the user is the environment upon which the agent, the recommendation system acts upon in order to receive a reward, for instance, a click or engagement by the user. One aspect of reinforcement learning that is of particular use in the area of recommender systems is the fact that the models or policies can be learned by providing a reward to the recommendation agent. This is in contrast to traditional learning techniques which rely on supervised learning approaches that are less flexible, reinforcement learning recommendation techniques allow to potentially train models that can be optimized directly on metrics of engagement, and user interest.</p>
                            <h5>f) Risk-aware recommender systems</h5>
                            <p>The majority of existing approaches to recommender systems focus on recommending the most relevant content to users using contextual information, yet do not take into account the risk of disturbing the user with unwanted notifications. It is important to consider the risk of upsetting the user by pushing recommendations in certain circumstances, for instance, during a professional meeting, early morning, or late at night. Therefore, the performance of the recommender system depends in part on the degree to which it has incorporated the risk into the recommendation process. One option to manage this issue is DRARS, a system which models the context-aware recommendation as a bandit problem. This system combines a content-based technique and a contextual bandit algorithm.</p>
                            <h5>g) Mobile recommender systems</h5>
                            <p>Mobile recommender systems make use of internet-accessing smart phones to offer personalized, context-sensitive recommendations. This is a particularly difficult area of research as mobile data is more complex than data that recommender systems often have to deal with. It is heterogeneous, noisy, requires spatial and temporal auto-correlation, and has validation and generality problems.</p>
                            <p>There are three factors that could affect the mobile recommender systems and the accuracy of prediction results: the context, the recommendation method and privacy. Additionally, mobile recommender systems suffer from a transplantation problem – recommendations may not apply in all regions (for instance, it would be unwise to recommend a recipe in an area where all of the ingredients may not be available).</p>
                            <p>One example of a mobile recommender system are the approaches taken by companies such as Uber and Lyft to generate driving routes for taxi drivers in a city. This system uses GPS data of the routes that taxi drivers take while working, which includes location (latitude and longitude), time stamps, and operational status (with or without passengers). It uses this data to recommend a list of pickup points along a route, with the goal of optimizing occupancy times and profits.</p>
                            <h5>h) Hybrid recommender systems</h5>
                            <p>Most recommender systems now use a hybrid approach, combining collaborative filtering, content-based filtering, and other approaches. There is no reason why several different techniques of the same type could not be hybridized. Hybrid approaches can be implemented in several ways: by making content-based and collaborative-based predictions separately and then combining them; by adding content-based capabilities to a collaborative-based approach (and vice versa); or by unifying the approaches into one model (see[24] for a complete review of recommender systems). Several studies that empirically compare the performance of the hybrid with the pure collaborative and content-based methods and demonstrated that the hybrid methods can provide more accurate recommendations than pure approaches. These methods can also be used to overcome some of the common problems in recommender systems such as cold start and the sparsity problem, as well as the knowledge engineering bottleneck in knowledge-based approaches.</p>
                            <p>Netflix is a good example of the use of hybrid recommender systems. The website makes recommendations by comparing the watching and searching habits of similar users (i.e., collaborative filtering) as well as by offering movies that share characteristics with films that a user has rated highly (content-based filtering).</p>
                            <p>Some hybridization techniques include:</p>
                            <ol>
                                <li><b>Weighted:</b> Combining the score of different recommendation components numerically.</li>
                                <li><b>Switching:</b> Choosing among recommendation components and applying the selected one.</li>
                                <li><b>Mixed:</b> Recommendations from different recommenders are presented together to give the recommendation.</li>
                                <li><b>Feature Combination:</b> Features derived from different knowledge sources are combined together and given to a single recommendation algorithm. </li>
                                <li><b>Feature Augmentation:</b> Computing a feature or set of features, which is then part of the input to the next technique. </li>
                                <li><b>Cascade:</b> Recommenders are given strict priority, with the lower priority ones breaking ties in the scoring of the higher ones.</li>
                                <li><b>Meta-level:</b> One recommendation technique is applied and produces some sort of model, which is then the input used by the next technique.</li>
                            </ol>
                            <br>
                            <h3>Process</h3>
                            <p>The process followed in developing a recommendation system involves:</p>
                            <ul>
                                <li>Data Collection</li>
                                <li>Pre-processing</li>
                                <li>Data mining</li>
                                <li>Vectorization</li>
                                <li>Training</li>
                                <li>Testing</li>
                            </ul>
                            <br>
                            <h4>Description</h4>
                            <ol>
                                <li>
                                    <h5>Data Collection :</h5>
                                </li>
                                <p>We have collected data sets from different open source websites for example : imdb , kaggle , Data.gov etc.</p>
                                <li>
                                    <h5>Pre-processing :</h5>
                                </li>
                                <p>We import all these four modules :-</p>
                                <ol>
                                    <li><b>Pandas :</b>Pandas is a Python library used for working with data sets.
                                        It has functions for analyzing, cleaning, exploring, and manipulating data.
                                        The name "Pandas" has a reference to both "Panel Data", and "Python Data Analysis" and was created by Wes McKinney in 2008.
                                    </li>
                                    <li><b>Numpy :</b>NumPy is a Python library used for working with arrays.
                                        It also has functions for working in domain of linear algebra, fourier transform, and matrices.
                                        NumPy was created in 2005 by Travis Oliphant. It is an open source project and you can use it freely.
                                        NumPy stands for Numerical Python.
                                    </li>
                                    <li><b>ast :</b>“ast” is a potential tool of python programming language which allows user to interact with python code itself and modify it.
                                        “ast” stands for “Abstract Syntax Tree”.
                                    </li>
                                    <li><b>Natural Language Toolkit(nltk) :</b> Library is a suite that contains libraries and programs for statistical language processing. It is one of the most powerful NLP libraries, which contains packages to make machines understand human language and reply to it with an appropriate response.
                                        <b>Natural Language Processing (NLP)</b> is a process of manipulating or understanding the text or speech by any software or machine. An analogy is that humans interact and understand each other’s views and respond with the appropriate answer. In NLP, this interaction, understanding, and response are made by a computer instead of a human.
                                    </li>
                                </ol>
                                <br>
                                <li>
                                    <h5>Data mining :</h5>
                                </li>
                                <p>Firstly we merge the movies having same “title” from both the data sets. We consider a few important parameters on basis of which we refine the data sets i.e. <b>“movie_id”, “title”, “overview”, “genres”, “keywords”, “cast”, “crew”.</b></p>
                                <p>Then we drop all those columns which have missing values in the data set and put <b>“NaN”</b> in the place of those missing values.</p>
                                <p>We convert all the list or object format data in the data sets to string format in according to data provided in the data sets.</p>
                                <p>After the data mining is done using the above essential parameters a new tagline is created by concatenating them. Then this tagline is put inside a new data frame along with their respective id and name. Then we convert the tagline into lower case.</p>
                                <p>Then we use <b>Porter stemming algorithm </b>(or ‘Porter stemmer’) which is a process for removing the commoner morphological and inflexional endings from words in English. It converts all the words having same meaning into its root words.</p>
                                <li>
                                    <h5>Vectorization :</h5>
                                </li>
                                <p><b>“Vectorization”</b> is a technique of implementing array operations without using for loops. Instead , we use functions defined by various modules which are highly optimized that reduces the running and execution time of code. Vectorized array operations will be faster than their pure Python equivalents , with the biggest impact in any kind of numerical computations.</p>
                                <p><b>“CountVectorizer”</b> is a great tool provided by scikit-learn library in Python. It is used to transform a given text into a vector on the basis of the frequency(count) of each word that occurs in the entire text. This is helpful when we have multiple such texts and we wish to convert each word in each text into vectors (for using in further text analysis).</p>
                                <p>After vectorization the desired data is converted to array form. The similarity between the vectors are checked . Then the similarity of every movie with the other movies is checked and stored into an array. Then we find the cosine distance between the vectors and compare the cosine distances of every item with the other items(The lesser is the cosine distance more is the similarity). Then we created a function that will recommend us the 5 most similar movies whenever any movie name is given.</p>
                                <p>Then a <b>final list</b> is prepared which consist of all the recommendations of movies ,serials, web series whenever any input will we provided by the user and this sheet is uploaded to the database of the website. </p>
                                <li>
                                    <h5>Training :</h5>
                                </li>
                                <p>Here in this model we have used approximately 5000 movies, serials and web series data which is used for training the model.</p>
                                <li>
                                    <h5>Testing :</h5>
                                </li>
                                <p>Our model will be recommending the best 10 movie names for each of the cases.</p>
                            </ol>
                        </ol>
                    </article>
                </div>
                <div class="col-md-4">
                    <div class="position-sticky" style="top: 2rem;">
                        <div class="p-4 mb-3 bg-light rounded">
                            <h4 class="fst-italic">About</h4>
                            <p class="mb-0">This is a mini blog on our Project i.e. about Recommendation System and the model is prepared based on the concept of Data mining. Read this blog to get a clear idea about our project.</p>
                        </div>
                        <div class="p-4">
                            <h4 class="fst-italic">Upcoming Releases</h4>
                            <ol class="list-unstyled mb-0">
                                <ul>
                                    <li><a href="https://www.imdb.com/calendar/?region=in">IMDb</a></li>
                                    <li><a href="https://www.bollywoodhungama.com/movie-release-dates/">Hungama</a></li>
                                    <li><a href="https://in.bookmyshow.com/explore/upcoming-movies">BookMyShow</a></li>
                                    </ul>
                            </ol>
                        </div>
                        <div class="p-4">
                            <h4 class="fst-italic">Elsewhere</h4>
                            <ol class="list-unstyled">
                                <ul>
                                    <li><a href="https://github.com/soumoofficial/Serial-Movies-and-Web-Series-Recommendation-System">GitHub</a></li>
                                    <li><a href="#">LinkedIn</a></li>
                                    <li><a href="#">Facebook</a></li>
                                </ul>
                            </ol>
                        </div>
                    </div>
                </div>
            </div>
        </main>
        <footer class="pt-3 mt-4 text-muted border-top">
            &copy; 2022
        </footer>
    </div>
